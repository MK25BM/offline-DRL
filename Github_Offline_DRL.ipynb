{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK25BM/offline-DRL/blob/main/Github_Offline_DRL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da5b741f"
      },
      "source": [
        "# Task\n",
        "\n",
        "Create a Gymnasium-compatible wrapper around simglucose (https://github.com/jxx123/simglucose) simulator instance. Generate some offline patient data using the simulator. Wrap the environment with Minari DataCollector.\n",
        "\n",
        "Using the above, demonstrate Offline Deep Reinforcement Learning (DRL) and Off-Policy Evaluation (OPE) by first defining an OpenAI Gym-compatible environment, implementing a behavior policy to collect an offline dataset, then implementing and training an Offline DRL algorithm on this dataset. Subsequently, implement and apply Off-Policy Evaluation (OPE) methods to estimate the performance of the trained offline policy using only the collected data. Finally, visualize the results, and summarize the demonstration, highlighting key findings, challenges of offline RL, and the utility of OPE."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redo verbose pipeline\n"
      ],
      "metadata": {
        "id": "EEoHhGZKvfVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library imports"
      ],
      "metadata": {
        "id": "_sJVuFwmxVOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import sys\n",
        "# import logging\n",
        "# from typing import Tuple, Any\n",
        "\n",
        "# def setup_dependencies() -> None:\n",
        "#     \"\"\"Install and import required packages.\"\"\"\n",
        "#     print(\"Setting up dependencies...\")\n",
        "\n",
        "#     # Aggressive clean uninstall and cache purge to ensure a fresh start\n",
        "#     !pip uninstall -y gym gymnasium numpy minari d3rlpy scipy scikit-learn\n",
        "#     !pip cache purge\n",
        "\n",
        "#     # Install d3rlpy (latest version) first to resolve its dependencies properly.\n",
        "#     !pip install -q d3rlpy --force-reinstall\n",
        "#     # Install other libraries (minari, gymnasium) without strong version pinning\n",
        "#     # so they can adapt to d3rlpy's installed dependencies if possible.\n",
        "#     !pip install -q minari gymnasium --force-reinstall\n",
        "\n",
        "#     print(\"OK All dependencies installed\\n\")\n",
        "\n",
        "# def import_libraries() -> Tuple[Any, Any, Any]:\n",
        "#     \"\"\"Import required libraries after installation.\"\"\"\n",
        "#     import gymnasium\n",
        "#     import d3rlpy\n",
        "#     import minari\n",
        "\n",
        "#     print(f\"OK All imports successful\")\n",
        "#     print(f\"   Minari version: {minari.__version__}\")\n",
        "#     print(f\"   d3rlpy version: {d3rlpy.__version__}\\n\") # Added d3rlpy version check\n",
        "\n",
        "#     return gymnasium, d3rlpy, minari\n",
        "\n",
        "# def setup_logging(verbose: bool = True) -> None:\n",
        "#     \"\"\"Configure logging for the pipeline.\"\"\"\n",
        "\n",
        "#     if verbose:\n",
        "#         # Keep INFO level for our custom messages\n",
        "#         logging.basicConfig(level=logging.INFO)\n",
        "#     else:\n",
        "#         # Suppress most logging\n",
        "#         logging.basicConfig(level=logging.WARNING)\n",
        "\n",
        "#     # Suppress d3rlpy's verbose logging\n",
        "#     logging.getLogger('d3rlpy').setLevel(logging.WARNING)\n",
        "#     logging.getLogger('minari').setLevel(logging.WARNING)\n",
        "\n",
        "# # Call setup_dependencies first to ensure packages are installed\n",
        "# setup_dependencies()\n",
        "\n",
        "# # Then import the libraries\n",
        "# gymnasium, d3rlpy, minari = import_libraries()"
      ],
      "metadata": {
        "id": "Bmj-E0NRphbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MOCK T1D ENVIRONMENT"
      ],
      "metadata": {
        "id": "x3ctRdZrxgGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import logging\n",
        "from typing import Tuple, Any, Optional, Dict # Added Optional, Dict for cleaner type hints\n",
        "\n",
        "# Aggressive clean uninstall and cache purge to ensure a fresh start with specific versions\n",
        "os.system('pip uninstall -y gym gymnasium numpy minari d3rlpy scipy scikit-learn 2>/dev/null')\n",
        "os.system('pip cache purge')\n",
        "\n",
        "# Install compatible versions forcefully, prioritizing d3rlpy's specific requirements\n",
        "# d3rlpy requires gymnasium==1.0.0 and numpy<2.0.0\n",
        "!pip install -q \"numpy==1.26.4\" --force-reinstall\n",
        "!pip install -q \"scipy==1.11.4\" --force-reinstall\n",
        "!pip install -q \"scikit-learn==1.3.2\" --force-reinstall\n",
        "!pip install -q \"gymnasium==1.0.0\" --force-reinstall # Crucial for d3rlpy compatibility\n",
        "!pip install -q \"d3rlpy==2.8.1\" --force-reinstall # Corrected d3rlpy version to an existing one\n",
        "!pip install -q \"minari\" --force-reinstall # Minari should be compatible with gymnasium==1.0.0\n",
        "\n",
        "# Verify imports\n",
        "import gymnasium\n",
        "import d3rlpy\n",
        "import minari\n",
        "import numpy as np\n",
        "\n",
        "print(f\"OK All imports successful after reinstallation attempt.\")\n",
        "print(f\"   Gymnasium version: {gymnasium.__version__}\")\n",
        "print(f\"   D3RLPy version: {d3rlpy.__version__}\")\n",
        "print(f\"   Minari version: {minari.__version__}\")\n",
        "print(f\"   NumPy version: {np.__version__}\")\n"
      ],
      "metadata": {
        "id": "jREkFdyEzWsN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69c2ee33-d7bd-4cb3-92ef-329f60886cdc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "libpysal 4.13.0 requires scikit-learn>=1.1, which is not installed.\n",
            "libpysal 4.13.0 requires scipy>=1.8, which is not installed.\n",
            "quantecon 0.10.1 requires scipy>=1.5.0, which is not installed.\n",
            "spglm 1.1.0 requires scipy>=1.8, which is not installed.\n",
            "cvxpy 1.6.7 requires scipy>=1.11.0, which is not installed.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, which is not installed.\n",
            "umap-learn 0.5.9.post2 requires scipy>=1.3.1, which is not installed.\n",
            "pysal 25.7 requires scikit-learn>=1.1, which is not installed.\n",
            "pysal 25.7 requires scipy>=1.8, which is not installed.\n",
            "statsmodels 0.14.6 requires scipy!=1.9.2,>=1.8, which is not installed.\n",
            "tsfresh 0.21.1 requires scikit-learn>=0.22.0, which is not installed.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", which is not installed.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, which is not installed.\n",
            "mlxtend 0.23.4 requires scipy>=1.2.1, which is not installed.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, which is not installed.\n",
            "hdbscan 0.8.41 requires scipy>=1.0, which is not installed.\n",
            "scs 3.2.9 requires scipy, which is not installed.\n",
            "segregation 2.5.3 requires scikit-learn>=0.21.3, which is not installed.\n",
            "segregation 2.5.3 requires scipy, which is not installed.\n",
            "pytensor 2.35.1 requires scipy<2,>=1, which is not installed.\n",
            "osqp 1.0.5 requires scipy>=0.13.2, which is not installed.\n",
            "imbalanced-learn 0.14.0 requires scikit-learn<2,>=1.4.2, which is not installed.\n",
            "imbalanced-learn 0.14.0 requires scipy<2,>=1.11.4, which is not installed.\n",
            "mapclassify 2.10.0 requires scikit-learn>=1.4, which is not installed.\n",
            "mapclassify 2.10.0 requires scipy>=1.12, which is not installed.\n",
            "spreg 1.8.4 requires scikit-learn>=0.22, which is not installed.\n",
            "spreg 1.8.4 requires scipy>=0.11, which is not installed.\n",
            "matplotlib-venn 1.1.2 requires scipy, which is not installed.\n",
            "fastai 2.8.6 requires scikit-learn, which is not installed.\n",
            "fastai 2.8.6 requires scipy, which is not installed.\n",
            "spaghetti 1.7.6 requires scipy>=1.8, which is not installed.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, which is not installed.\n",
            "yellowbrick 1.5 requires scipy>=1.0.0, which is not installed.\n",
            "mgwr 2.2.1 requires scipy>=0.11, which is not installed.\n",
            "xgboost 3.1.2 requires scipy, which is not installed.\n",
            "access 1.1.10.post3 requires scipy>=1.14.1, which is not installed.\n",
            "pymc 5.26.1 requires scipy>=1.4.1, which is not installed.\n",
            "spopt 0.7.0 requires scikit-learn>=1.4.0, which is not installed.\n",
            "spopt 0.7.0 requires scipy>=1.12.0, which is not installed.\n",
            "hyperopt 0.2.7 requires scipy, which is not installed.\n",
            "lightgbm 4.6.0 requires scipy, which is not installed.\n",
            "plotnine 0.14.5 requires scipy>=1.8.0, which is not installed.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, which is not installed.\n",
            "missingno 0.5.2 requires scipy, which is not installed.\n",
            "albumentations 2.0.8 requires scipy>=1.10.0, which is not installed.\n",
            "shap 0.50.0 requires scikit-learn, which is not installed.\n",
            "shap 0.50.0 requires scipy, which is not installed.\n",
            "jaxlib 0.7.2 requires scipy>=1.13, which is not installed.\n",
            "clarabel 0.11.1 requires scipy, which is not installed.\n",
            "spint 1.0.7 requires scipy>=0.11, which is not installed.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, which is not installed.\n",
            "esda 2.8.0 requires scikit-learn>=1.4, which is not installed.\n",
            "esda 2.8.0 requires scipy>=1.12, which is not installed.\n",
            "pointpats 2.5.2 requires scipy>=1.10, which is not installed.\n",
            "stumpy 1.13.0 requires scipy>=1.10, which is not installed.\n",
            "librosa 0.11.0 requires scikit-learn>=1.1.0, which is not installed.\n",
            "librosa 0.11.0 requires scipy>=1.6.0, which is not installed.\n",
            "tobler 0.12.1 requires scipy, which is not installed.\n",
            "giddy 2.3.8 requires scipy>=1.12, which is not installed.\n",
            "inequality 1.1.2 requires scipy>=1.12, which is not installed.\n",
            "xarray-einstats 0.9.1 requires scipy>=1.11, which is not installed.\n",
            "mizani 0.13.5 requires scipy>=1.8.0, which is not installed.\n",
            "pynndescent 0.5.13 requires scikit-learn>=0.18, which is not installed.\n",
            "pynndescent 0.5.13 requires scipy>=1.0, which is not installed.\n",
            "arviz 0.22.0 requires scipy>=1.11.0, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scikit-learn>=0.23.0, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scipy>=1.5.1, which is not installed.\n",
            "jax 0.7.2 requires scipy>=1.13, which is not installed.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "torchvision 0.24.0+cpu requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "bigframes 2.30.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.8/35.8 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "libpysal 4.13.0 requires scikit-learn>=1.1, which is not installed.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, which is not installed.\n",
            "pysal 25.7 requires scikit-learn>=1.1, which is not installed.\n",
            "tsfresh 0.21.1 requires scikit-learn>=0.22.0, which is not installed.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, which is not installed.\n",
            "sentence-transformers 5.2.0 requires scikit-learn, which is not installed.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, which is not installed.\n",
            "segregation 2.5.3 requires scikit-learn>=0.21.3, which is not installed.\n",
            "imbalanced-learn 0.14.0 requires scikit-learn<2,>=1.4.2, which is not installed.\n",
            "mapclassify 2.10.0 requires scikit-learn>=1.4, which is not installed.\n",
            "spreg 1.8.4 requires scikit-learn>=0.22, which is not installed.\n",
            "fastai 2.8.6 requires scikit-learn, which is not installed.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, which is not installed.\n",
            "spopt 0.7.0 requires scikit-learn>=1.4.0, which is not installed.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, which is not installed.\n",
            "shap 0.50.0 requires scikit-learn, which is not installed.\n",
            "esda 2.8.0 requires scikit-learn>=1.4, which is not installed.\n",
            "librosa 0.11.0 requires scikit-learn>=1.1.0, which is not installed.\n",
            "pynndescent 0.5.13 requires scikit-learn>=0.18, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scikit-learn>=0.23.0, which is not installed.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\n",
            "torchvision 0.24.0+cpu requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "mapclassify 2.10.0 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "bigframes 2.30.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "access 1.1.10.post3 requires scipy>=1.14.1, but you have scipy 1.11.4 which is incompatible.\n",
            "spopt 0.7.0 requires scipy>=1.12.0, but you have scipy 1.11.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "esda 2.8.0 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "giddy 2.3.8 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "inequality 1.1.2 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, which is not installed.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "torchvision 0.24.0+cpu requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "imbalanced-learn 0.14.0 requires scikit-learn<2,>=1.4.2, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "mapclassify 2.10.0 requires scikit-learn>=1.4, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "bigframes 2.30.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "spopt 0.7.0 requires scikit-learn>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "esda 2.8.0 requires scikit-learn>=1.4, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n",
            "scikit-learn 1.3.2 requires numpy<2.0,>=1.17.3, but you have numpy 2.4.0 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "torchvision 0.24.0+cpu requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.0 which is incompatible.\n",
            "imbalanced-learn 0.14.0 requires scikit-learn<2,>=1.4.2, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "mapclassify 2.10.0 requires scikit-learn>=1.4, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "bigframes 2.30.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "spopt 0.7.0 requires scikit-learn>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.0 which is incompatible.\n",
            "esda 2.8.0 requires scikit-learn>=1.4, but you have scikit-learn 1.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.1/201.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m730.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m812.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "torchvision 0.24.0+cpu requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.0 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "bigframes 2.30.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: typer 0.21.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.1/952.1 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "d3rlpy 2.8.1 requires gymnasium==1.0.0, but you have gymnasium 1.2.3 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "torchvision 0.24.0+cpu requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.0 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.0 which is incompatible.\n",
            "bigframes 2.30.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name '_center' from 'numpy._core.umath' (/usr/local/lib/python3.12/dist-packages/numpy/_core/umath.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1071075802.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Verify imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgymnasium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0md3rlpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mminari\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/d3rlpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from . import (\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0malgos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/d3rlpy/algos/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mqlearning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutility\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/d3rlpy/algos/qlearning/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnfq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mplas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprdc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrandom_policy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrebrac\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/d3rlpy/algos/qlearning/prdc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: E402 F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_missing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_pandas_na\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_scalar_nan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_html\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReprHTMLMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Make _safe_indexing importable from here for backward compat as this particular\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_importlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from ._sputils import (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[0m\u001b[1;32m      9\u001b[0m                        \u001b[0mget_sum_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misdense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_todata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                        matrix, validateaxis, getdtype, is_pydata_spmatrix)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/sparse/_sputils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_ulong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m from scipy._lib._array_api import (Array, array_namespace, is_lazy_array,\n\u001b[0m\u001b[1;32m     15\u001b[0m                                    \u001b[0mis_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp_result_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                    xp_size, xp_result_type)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/_lib/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_api_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m from scipy._lib.array_api_compat import (\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mis_array_api_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mis_lazy_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/_lib/array_api_compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403  # pyright: ignore[reportWildcardImportFromLibrary]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# from numpy import * doesn't overwrite these builtin names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mpromote_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mptp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0mputmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mrad2deg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/char/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefchararray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefchararray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__all__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/defchararray.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiarray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompare_chararrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m from numpy._core.strings import (\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0m_join\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0m_rsplit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrsplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/strings.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiarray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_vec_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_function_dispatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from numpy._core.umath import (\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0m_center\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0m_expandtabs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_center' from 'numpy._core.umath' (/usr/local/lib/python3.12/dist-packages/numpy/_core/umath.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# MOCK T1D ENVIRONMENT\n",
        "# ============================================================================\n",
        "\n",
        "class MockT1DEnv:\n",
        "    \"\"\"Mock Type 1 Diabetes environment for offline RL training.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize mock environment.\"\"\"\n",
        "        self.current_glucose = 120.0\n",
        "        self.time_step = 0\n",
        "        self.max_steps = 480\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the environment.\"\"\"\n",
        "        min_glucose = 100.0\n",
        "        max_glucose = 150.0\n",
        "        self.current_glucose = np.random.uniform(min_glucose, max_glucose)\n",
        "        self.time_step = 0\n",
        "        return self.current_glucose\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Step the environment.\"\"\"\n",
        "        action = float(action)\n",
        "        baseline = 15.0\n",
        "        mean_noise = 0.0\n",
        "        std_noise = 5.0\n",
        "        noise = np.random.normal(mean_noise, std_noise)\n",
        "        factor = 0.5\n",
        "        delta = (action - baseline) * factor + noise\n",
        "        self.current_glucose = self.current_glucose + delta\n",
        "        self.current_glucose = np.clip(self.current_glucose, 40.0, 300.0)\n",
        "\n",
        "        self.time_step = self.time_step + 1\n",
        "        done = self.time_step >= self.max_steps\n",
        "\n",
        "        if self.current_glucose < 70.0:\n",
        "            reward = -1.0\n",
        "        elif self.current_glucose > 180.0:\n",
        "            reward = -0.5\n",
        "        else:\n",
        "            reward = 1.0\n",
        "\n",
        "        info = {'glucose': self.current_glucose}\n",
        "\n",
        "        return self.current_glucose, reward, done, info\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"Close environment.\"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# SIMGLUCOSE ENVIRONMENT WRAPPER - DIRECT INSTANTIATION (Now wraps MockT1DEnv)\n",
        "# ============================================================================\n",
        "\n",
        "class SimglucoseGymEnv(gymnasium.Env):\n",
        "    \"\"\"\n",
        "    Gymnasium-compatible wrapper for SimGlucose T1DSimEnv.\n",
        "    Now directly instantiates MockT1DEnv due to simglucose dependency issues.\n",
        "    \"\"\"\n",
        "\n",
        "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 30}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        patient_name: str = 'adolescent#001',\n",
        "        seed: Optional[int] = None,\n",
        "        render_mode: Optional[str] = None\n",
        "    ):\n",
        "        \"\"\"Initialize the SimglucoseGymEnv.\"\"\"\n",
        "        super().__init__() # Removed seed=seed here\n",
        "\n",
        "        self.render_mode = render_mode\n",
        "        self.patient_name = patient_name\n",
        "        self._episode_steps = 0\n",
        "        self._max_episode_steps = 480\n",
        "        self._episode_rewards = []\n",
        "        self._last_obs = None\n",
        "\n",
        "        # Use MockT1DEnv instead of T1DSimEnv due to dependency conflicts\n",
        "        self.env = MockT1DEnv()\n",
        "        print(f\"OK Successfully initialized MockT1DEnv (instead of T1DSimEnv due to compatibility issues).\")\n",
        "\n",
        "        self.action_space = gymnasium.spaces.Box(\n",
        "            low=np.float32(0.0),\n",
        "            high=np.float32(30.0),\n",
        "            shape=(1,),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        self.observation_space = gymnasium.spaces.Box(\n",
        "            low=np.float32(0.0),\n",
        "            high=np.float32(1000.0),\n",
        "            shape=(1,),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # Ensure reproducibility for internal random operations if seed is provided\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "\n",
        "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, float, bool, bool, dict]:\n",
        "        \"\"\"Perform one step in the environment.\"\"\"\n",
        "        if isinstance(action, np.ndarray):\n",
        "            scalar_action = float(action[0]) if action.size == 1 else float(action)\n",
        "        else:\n",
        "            scalar_action = float(action)\n",
        "\n",
        "        try:\n",
        "            observation, reward, done, info = self.env.step(scalar_action)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR in step: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "        self._episode_steps += 1\n",
        "        self._episode_rewards.append(float(reward))\n",
        "\n",
        "        if observation is None:\n",
        "            observation = self._last_obs if self._last_obs is not None else np.array([0.0], dtype=np.float32)\n",
        "        else:\n",
        "            if not isinstance(observation, np.ndarray):\n",
        "                observation = np.array([float(observation)], dtype=np.float32)\n",
        "            else:\n",
        "                if observation.ndim == 0:\n",
        "                    observation = np.array([float(observation)], dtype=np.float32)\n",
        "                elif observation.shape == (1,):\n",
        "                    observation = observation.astype(np.float32)\n",
        "                else:\n",
        "                    observation = np.array([float(observation.flat[0])], dtype=np.float32)\n",
        "            self._last_obs = observation.copy()\n",
        "\n",
        "        truncated = self._episode_steps >= self._max_episode_steps\n",
        "\n",
        "        return observation, float(reward), bool(done), truncated, info\n",
        "\n",
        "    def reset(\n",
        "        self,\n",
        "        seed: Optional[int] = None,\n",
        "        options: Optional[dict] = None\n",
        "    ) -> Tuple[np.ndarray, dict]:\n",
        "        \"\"\"Reset the environment.\"\"\"\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        try:\n",
        "            # If a seed is provided to reset, ensure MockT1DEnv uses it for reproducibility\n",
        "            if seed is not None:\n",
        "                np.random.seed(seed)\n",
        "            observation = self.env.reset()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR in reset: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "        if observation is None:\n",
        "            observation = np.array([0.0], dtype=np.float32)\n",
        "        else:\n",
        "            if not isinstance(observation, np.ndarray):\n",
        "                observation = np.array([float(observation)], dtype=np.float32)\n",
        "            else:\n",
        "                if observation.ndim == 0:\n",
        "                    observation = np.array([float(observation)], dtype=np.float32)\n",
        "                elif observation.shape == (1,):\n",
        "                    observation = observation.astype(np.float32)\n",
        "                else:\n",
        "                    observation = np.array([float(observation.flat[0])], dtype=np.float32)\n",
        "\n",
        "        self._last_obs = observation.copy()\n",
        "        self._episode_steps = 0\n",
        "        self._episode_rewards = []\n",
        "\n",
        "        return observation, {}\n",
        "\n",
        "    def render(self) -> Optional[Any]:\n",
        "        \"\"\"Render the environment (if applicable).\"\"\"\n",
        "        return None\n",
        "\n",
        "    def close(self) -> None:\n",
        "        \"\"\"Close the environment and cleanup resources.\"\"\"\n",
        "        if hasattr(self, 'env'):\n",
        "            self.env.close()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# ENVIRONMENT SETUP AND TESTING\n",
        "# ============================================================================\n",
        "\n",
        "def setup_simglucose_environment(\n",
        "    patient_name: str = 'adolescent#001',\n",
        "    seed: int = 42\n",
        ") -> SimglucoseGymEnv:\n",
        "    \"\"\"Setup and initialize a SimGlucose environment.\"\"\"\n",
        "    print(\"Initializing SimglucoseGymEnv...\")\n",
        "    env = SimglucoseGymEnv(patient_name=patient_name, seed=seed)\n",
        "    print(\"OK SimglucoseGymEnv initialized successfully!\")\n",
        "    return env\n",
        "\n",
        "\n",
        "def test_environment(env: SimglucoseGymEnv, n_steps: int = 5) -> None:\n",
        "    \"\"\"Test the environment with random actions.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"Testing Environment with Random Actions\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    obs, info = env.reset(seed=42)\n",
        "    print(f\"\\nOK Reset successful!\")\n",
        "    print(f\"Initial Observation: {obs}\")\n",
        "\n",
        "    print(\"\\n--- Testing Steps ---\")\n",
        "    episode_rewards = []\n",
        "\n",
        "    for i in range(n_steps):\n",
        "        action = env.action_space.sample()\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        episode_rewards.append(reward)\n",
        "\n",
        "        print(f\"Step {i + 1}: obs={obs[0]:.2f}, reward={reward:.4f}\")\n",
        "\n",
        "        if terminated or truncated:\n",
        "            print(\"  Episode ended!\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\n--- Episode Summary ---\")\n",
        "    print(f\"  Total Steps: {len(episode_rewards)}\")\n",
        "    print(f\"  Total Return: {sum(episode_rewards):.4f}\")\n",
        "    print(f\"  Average Reward: {np.mean(episode_rewards):.4f}\")\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "\n",
        "def define_behavior_policy(observation: np.ndarray, env: SimglucoseGymEnv) -> np.ndarray:\n",
        "    \"\"\"Simple random behavior policy for data collection.\"\"\"\n",
        "    return env.action_space.sample()"
      ],
      "metadata": {
        "id": "qvUQNZFOrd51"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection"
      ],
      "metadata": {
        "id": "8878GPOPxsTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from typing import Callable\n",
        "from minari import DataCollector\n",
        "\n",
        "# ============================================================================\n",
        "# DATA COLLECTION\n",
        "# ============================================================================\n",
        "\n",
        "def setup_data_collection(\n",
        "    env: SimglucoseGymEnv,\n",
        "    num_episodes: int = 10,\n",
        "    max_steps_per_episode: int = 480,\n",
        "    dataset_name: str = None  # Add this parameter\n",
        ") -> Tuple[str, DataCollector]: # Modified to return DataCollector\n",
        "    \"\"\"Setup and prepare data collection with Minari DataCollector.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"Setting up Minari Data Collection\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Use provided dataset_name or generate one\n",
        "    if dataset_name is None:\n",
        "        timestamp = time.strftime(\"%Y%m%d%H%M%S\")\n",
        "        dataset_name = f'simglucose/adolescent/random-v{timestamp}'\n",
        "\n",
        "    print(f\"\\nCreating DataCollector for dataset '{dataset_name}'...\")\n",
        "    # Initialize Minari DataCollector without dataset_id in constructor\n",
        "    data_collector = DataCollector(env, record_infos=True)\n",
        "    print(\"OK DataCollector created successfully!\")\n",
        "\n",
        "    print(f\"\\nData Collection Parameters:\")\n",
        "    print(f\"  - Dataset Name: {dataset_name}\")\n",
        "    print(f\"  - Number of Episodes: {num_episodes}\")\n",
        "    print(f\"  - Max Steps per Episode: {max_steps_per_episode}\")\n",
        "\n",
        "    return dataset_name, data_collector\n",
        "\n",
        "\n",
        "def collect_data_simple(\n",
        "    env:   SimglucoseGymEnv,\n",
        "    policy:  Callable,\n",
        "    num_episodes:  int = 10,\n",
        "    max_steps_per_episode: int = 480,\n",
        "    dataset_name: str = 'simglucose-adolescent-random-v0',\n",
        "    verbose: bool = True\n",
        "):\n",
        "    \"\"\"Collect trajectory data and return as dictionary.\"\"\"\n",
        "    if verbose:\n",
        "        print(f\"\\nStarting data collection for {num_episodes} episodes...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "    episodes_data = []\n",
        "\n",
        "    for episode_num in range(num_episodes):\n",
        "        observations = []\n",
        "        actions = []\n",
        "        rewards = []\n",
        "        terminations = []\n",
        "        truncations = []\n",
        "\n",
        "        obs, _ = env.reset()\n",
        "\n",
        "        for step in range(max_steps_per_episode):\n",
        "            observations.append(obs.  copy())\n",
        "            action = policy(obs, env)\n",
        "            actions.append(action)\n",
        "\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "            rewards.append(reward)\n",
        "            terminations.append(terminated)\n",
        "            truncations.append(truncated)\n",
        "\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "\n",
        "        episode_dict = {\n",
        "            'observations': np.array(observations),\n",
        "            'actions': np.array(actions),\n",
        "            # ✅ Reshape rewards to 2D:  (n_steps, 1)\n",
        "            'rewards': np.array(rewards, dtype=np.float32).reshape(-1, 1),\n",
        "            'terminations': np.array(terminations),\n",
        "            'truncations': np.  array(truncations),\n",
        "        }\n",
        "        episodes_data.append(episode_dict)\n",
        "\n",
        "    elapsed_time = time.time() - start_time if verbose else None\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"OK Data collection complete! (took {elapsed_time:.2f}s)\")\n",
        "        print(f\"Collected {len(episodes_data)} episodes\")\n",
        "        print(f\"   Total transitions: {sum(len(ep['rewards']) for ep in episodes_data)}\")\n",
        "\n",
        "    return episodes_data\n",
        "\n",
        "\n",
        "def collect_data_and_save(\n",
        "    num_episodes: int = 10,\n",
        "    max_steps_per_episode: int = 480,\n",
        "    patient_name: str = 'adolescent#001',\n",
        "    policy_type: str = 'random'\n",
        "):\n",
        "    \"\"\"Complete SimGlucose environment setup and data collection pipeline.\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"SimGlucose Environment Setup and Data Collection\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    env = setup_simglucose_environment(patient_name=patient_name, seed=42)\n",
        "    test_environment(env, n_steps=5)\n",
        "\n",
        "    policy = define_behavior_policy\n",
        "    print(\"\\nOK Using random policy\")\n",
        "\n",
        "    episodes_data = collect_data_simple(\n",
        "        env=env,\n",
        "        policy=policy,\n",
        "        num_episodes=num_episodes,\n",
        "        max_steps_per_episode=max_steps_per_episode,\n",
        "        dataset_name=None,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    env.close()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"OK Data Collection Pipeline Complete!\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    return episodes_data"
      ],
      "metadata": {
        "id": "tjS3du7-rhlE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET MANAGEMENT"
      ],
      "metadata": {
        "id": "V2vj1GPqx67O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from minari import MinariDataset, load_dataset, create_dataset_from_buffers\n",
        "import time\n",
        "\n",
        "# ============================================================================\n",
        "# MINARI DATASET MANAGEMENT & REPLAY BUFFER MANAGEMENT\n",
        "# ============================================================================\n",
        "\n",
        "class MinariDatasetLoader:\n",
        "    \"\"\"Handler for loading and managing Minari datasets.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_dataset(dataset_name: str = 'simglucose-adolescent-random-v0') -> MinariDataset:\n",
        "        \"\"\"Load a Minari dataset.\"\"\"\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Loading Minari Dataset:  {dataset_name}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        try:\n",
        "            # Try loading the exact dataset_name passed, which might be a pre-existing one\n",
        "            # or a freshly generated unique one from collect_data_and_save.\n",
        "            dataset = load_dataset(dataset_name, download=False)\n",
        "            print(f\"OK Dataset loaded successfully!\")\n",
        "            print(f\"  - Total episodes: {len(dataset.episodes)}\")\n",
        "            total_transitions = sum(ep.transition_count for ep in dataset.episodes)\n",
        "            print(f\"  - Total transitions: {total_transitions}\")\n",
        "            return dataset\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Dataset '{dataset_name}' not found locally. Collecting new data...\")\n",
        "            # If not found, generate a unique name and collect new data\n",
        "            timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "            unique_dataset_name = f'simglucose-adolescent-random-v0-{timestamp}'\n",
        "\n",
        "            # Collect raw episode data\n",
        "            episodes_data_raw = collect_data_and_save(\n",
        "                num_episodes=10,\n",
        "                max_steps_per_episode=480,\n",
        "                patient_name='adolescent#001',\n",
        "                policy_type='random'\n",
        "            )\n",
        "\n",
        "            # Convert raw episode data to MinariDataset\n",
        "            observations_list = [ep['observations'] for ep in episodes_data_raw]\n",
        "            actions_list = [ep['actions'] for ep in episodes_data_raw]\n",
        "            rewards_list_flat = [ep['rewards'].flatten() for ep in episodes_data_raw] # Flatten rewards to (N,)\n",
        "            terminations_list = [ep['terminations'] for ep in episodes_data_raw]\n",
        "            truncations_list = [ep['truncations'] for ep in episodes_data_raw]\n",
        "\n",
        "            # We need to provide observation and action spaces to create_dataset_from_buffers\n",
        "            # Temporarily create an environment to get its spaces\n",
        "            temp_env = SimglucoseGymEnv(patient_name='adolescent#001', seed=42)\n",
        "            observation_space = temp_env.observation_space\n",
        "            action_space = temp_env.action_space\n",
        "            temp_env.close()\n",
        "\n",
        "            new_dataset = create_dataset_from_buffers(\n",
        "                dataset_id=unique_dataset_name,\n",
        "                observations=observations_list,\n",
        "                actions=actions_list,\n",
        "                rewards=rewards_list_flat,\n",
        "                terminations=terminations_list,\n",
        "                truncations=truncations_list,\n",
        "                observation_space=observation_space,\n",
        "                action_space=action_space\n",
        "            )\n",
        "            print(f\"OK New Minari Dataset '{unique_dataset_name}' created from collected data!\")\n",
        "            return new_dataset\n",
        "\n",
        "    @staticmethod\n",
        "    def dataset_statistics(dataset: MinariDataset) -> Dict[str, Any]:\n",
        "        \"\"\"Compute statistics about the dataset.\"\"\"\n",
        "        episodes = dataset.episodes\n",
        "        episode_returns = []\n",
        "        episode_lengths = []\n",
        "        rewards_list = []\n",
        "\n",
        "        for episode in episodes:\n",
        "            episode_reward = 0.0\n",
        "            for i in range(episode.transition_count):\n",
        "                transition = episode[i]\n",
        "                episode_reward += transition.reward\n",
        "                rewards_list.append(transition.reward)\n",
        "            episode_returns.append(episode_reward)\n",
        "            episode_lengths.append(episode.transition_count)\n",
        "\n",
        "        stats = {\n",
        "            'num_episodes': len(episodes),\n",
        "            'total_transitions': sum(episode_lengths),\n",
        "            'mean_episode_return': float(np.mean(episode_returns)),\n",
        "            'std_episode_return': float(np.std(episode_returns)),\n",
        "            'max_episode_return': float(np.max(episode_returns)),\n",
        "            'min_episode_return': float(np.min(episode_returns)),\n",
        "            'mean_episode_length': float(np.mean(episode_lengths)),\n",
        "            'mean_reward': float(np.mean(rewards_list)),\n",
        "            'std_reward': float(np.std(rewards_list)),\n",
        "        }\n",
        "        return stats\n",
        "\n",
        "    @staticmethod\n",
        "    def print_statistics(stats: Dict[str, Any]) -> None:\n",
        "        \"\"\"Print dataset statistics.\"\"\"\n",
        "        print(f\"\\nDataset Statistics:\")\n",
        "        print(f\"  Episodes: {stats['num_episodes']}\")\n",
        "        print(f\"  Total Transitions: {stats['total_transitions']}\")\n",
        "        print(f\"  Mean Episode Return: {stats['mean_episode_return']:.4f} +/- {stats['std_episode_return']:.4f}\")\n",
        "        print(f\"  Mean Episode Length: {stats['mean_episode_length']:.1f}\")\n",
        "        print(f\"  Mean Reward: {stats['mean_reward']:.4f} +/- {stats['std_reward']:.4f}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# REPLAY BUFFER MANAGEMENT\n",
        "# ============================================================================\n",
        "\n",
        "class ReplayBufferManager:\n",
        "    \"\"\"Handler for converting Minari datasets to d3rlpy ReplayBuffer.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def create_replay_buffer(dataset: MinariDataset) -> Any:\n",
        "        \"\"\"Convert Minari dataset to d3rlpy ReplayBuffer.\"\"\"\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"Converting Minari Dataset to d3rlpy ReplayBuffer\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        try:\n",
        "            replay_buffer = d3rlpy.dataset.create_replay_buffer(\n",
        "                episodes=dataset.episodes\n",
        "            )\n",
        "            print(f\"OK ReplayBuffer created successfully!\")\n",
        "            print(f\"  - Size: {len(replay_buffer)} transitions\")\n",
        "            return replay_buffer\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR creating replay buffer: {e}\")\n",
        "            raise"
      ],
      "metadata": {
        "id": "Jk95HYg8x4ae"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFFLINE RL ALGORITHM CONFIGURATION & TRAINING\n"
      ],
      "metadata": {
        "id": "RHynWrH9yB-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# OFFLINE RL ALGORITHM CONFIGURATION\n",
        "# ============================================================================\n",
        "import d3rlpy\n",
        "\n",
        "class OfflineRLAlgorithm:\n",
        "    \"\"\"Factory for creating offline RL algorithms.\"\"\"\n",
        "\n",
        "    ALGORITHM_CONFIGS = {\n",
        "        'cql': {\n",
        "            'name': 'Conservative Q-Learning (CQL)',\n",
        "            'description': 'Best for general offline RL',\n",
        "            'config_class': d3rlpy.algos.CQLConfig,\n",
        "            'params': {\n",
        "                'actor_learning_rate': 1e-4,\n",
        "                'critic_learning_rate': 3e-4,\n",
        "                'batch_size': 256,\n",
        "                'gamma': 0.99,\n",
        "                'tau': 5e-3,\n",
        "                'alpha_learning_rate': 1e-4,\n",
        "                'conservative_weight': 10.0,\n",
        "                'n_action_samples': 10,\n",
        "            }\n",
        "        },\n",
        "        'iql': {\n",
        "            'name':  'Implicit Q-Learning (IQL)',\n",
        "            'description': 'Avoids querying unseen actions',\n",
        "            'config_class':  d3rlpy.algos.IQLConfig,\n",
        "            'params': {\n",
        "                'actor_learning_rate': 3e-4,\n",
        "                'critic_learning_rate': 3e-4,\n",
        "                'batch_size': 256,\n",
        "                'gamma': 0.99,\n",
        "                'tau': 5e-3,\n",
        "                'expectile':  0.7,\n",
        "                'weight_temp': 3.0,\n",
        "                'max_weight': 100.0,\n",
        "            }\n",
        "        },\n",
        "        'bc': {\n",
        "            'name': 'Behavioral Cloning (BC)',\n",
        "            'description': 'Simple imitation learning baseline',\n",
        "            'config_class':  d3rlpy.algos.BCConfig,\n",
        "            'params': {\n",
        "                'learning_rate': 1e-4,\n",
        "                'batch_size': 256,\n",
        "            }\n",
        "        },\n",
        "    }\n",
        "\n",
        "    @classmethod\n",
        "    def list_algorithms(cls) -> None:\n",
        "        \"\"\"List available algorithms.\"\"\"\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"Available Offline RL Algorithms\")\n",
        "        print(f\"{'='*80}\")\n",
        "        for algo_type, config in cls.ALGORITHM_CONFIGS.items():\n",
        "            print(f\"\\n  {algo_type.upper()}:\\n    Name: {config['name']}\\n    Description: {config['description']}\")\n",
        "\n",
        "    @classmethod\n",
        "    def create(cls, algo_type: str = 'cql', device: str = 'cpu:0', **custom_params):\n",
        "        \"\"\"Create an offline RL algorithm.\"\"\"\n",
        "        algo_type = algo_type.lower()\n",
        "\n",
        "        if algo_type not in cls.ALGORITHM_CONFIGS:\n",
        "            raise ValueError(f\"Unknown algorithm:  {algo_type}\")\n",
        "\n",
        "        config_info = cls.ALGORITHM_CONFIGS[algo_type]\n",
        "        params = config_info['params'].copy()\n",
        "        params.update(custom_params)\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Creating {config_info['name']}\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"Device: {device}\")\n",
        "        print(f\"\\nHyperparameters:\")\n",
        "        for key, value in params.items():\n",
        "            print(f\"  - {key}: {value}\")\n",
        "\n",
        "        config = config_info['config_class'](**params)\n",
        "        algo = config.create(device=device)\n",
        "\n",
        "        print(f\"OK {config_info['name']} created successfully!\")\n",
        "        return algo\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "class OfflineRLTrainer:\n",
        "    \"\"\"Trainer for offline RL algorithms.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def train(\n",
        "        algo,\n",
        "        replay_buffer,\n",
        "        n_steps:  int = 50000,\n",
        "        save_interval: int = 5000,\n",
        "        verbose: bool = True\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Train offline RL algorithm.\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Starting Offline RL Training\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"Training Configuration:\")\n",
        "        print(f\"  - Algorithm: {algo.__class__.__name__}\")\n",
        "        print(f\"  - Total Steps: {n_steps}\")\n",
        "        # ✅ Use . size() instead of len()\n",
        "        print(f\"  - Replay Buffer Size: {replay_buffer.size()}\")\n",
        "        print()\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # Train the algorithm\n",
        "            algo.fit(\n",
        "                replay_buffer,\n",
        "                n_steps=n_steps,\n",
        "                show_progress=verbose\n",
        "            )\n",
        "\n",
        "            training_time = time.time() - start_time\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"\\nOK Training complete!\")\n",
        "                print(f\"  - Training Time: {training_time:.2f}s\") # Fixed f-string format\n",
        "                print(f\"  - Steps per Second: {n_steps / training_time:.2f}\")\n",
        "\n",
        "            return {\n",
        "                'n_steps': n_steps,\n",
        "                'training_time': training_time,\n",
        "                'steps_per_second': n_steps / training_time\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            if verbose:\n",
        "                print(f\"ERROR during training: {e}\")\n",
        "            raise\n"
      ],
      "metadata": {
        "id": "sKeZWyvvrhoL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "a26839f0-9b8b-46fa-fcf3-a8f700eba8d2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name '_center' from 'numpy._core.umath' (/usr/local/lib/python3.12/dist-packages/numpy/_core/umath.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2664621370.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# OFFLINE RL ALGORITHM CONFIGURATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0md3rlpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mOfflineRLAlgorithm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/d3rlpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from . import (\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0malgos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/d3rlpy/algos/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mqlearning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutility\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/d3rlpy/algos/qlearning/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnfq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mplas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprdc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrandom_policy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrebrac\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/d3rlpy/algos/qlearning/prdc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: E402 F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_missing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_pandas_na\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_scalar_nan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_html\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReprHTMLMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Make _safe_indexing importable from here for backward compat as this particular\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_importlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from ._sputils import (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[0m\u001b[1;32m      9\u001b[0m                        \u001b[0mget_sum_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misdense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_todata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                        matrix, validateaxis, getdtype, is_pydata_spmatrix)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/sparse/_sputils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_ulong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m from scipy._lib._array_api import (Array, array_namespace, is_lazy_array,\n\u001b[0m\u001b[1;32m     15\u001b[0m                                    \u001b[0mis_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp_result_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                    xp_size, xp_result_type)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/_lib/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_api_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m from scipy._lib.array_api_compat import (\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mis_array_api_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mis_lazy_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/_lib/array_api_compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403  # pyright: ignore[reportWildcardImportFromLibrary]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# from numpy import * doesn't overwrite these builtin names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mpromote_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mptp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0mputmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mrad2deg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/char/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefchararray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefchararray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__all__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/defchararray.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiarray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompare_chararrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m from numpy._core.strings import (\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0m_join\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0m_rsplit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrsplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/strings.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiarray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_vec_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_function_dispatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from numpy._core.umath import (\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0m_center\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0m_expandtabs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_center' from 'numpy._core.umath' (/usr/local/lib/python3.12/dist-packages/numpy/_core/umath.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVALUATION & MODEL PERSISTENCE"
      ],
      "metadata": {
        "id": "44WfTjaeyRxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "class PolicyEvaluator:\n",
        "    \"\"\"Handler for evaluating trained policies.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def evaluate(\n",
        "        algo,\n",
        "        env,\n",
        "        n_episodes: int = 5,\n",
        "        max_steps:  Optional[int] = None,\n",
        "        verbose: bool = True\n",
        "    ) -> Dict[str, float]:\n",
        "        \"\"\"Evaluate a trained policy.\"\"\"\n",
        "        if verbose:\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(f\"Evaluating Policy ({n_episodes} episodes)\")\n",
        "            print(f\"{'='*80}\")\n",
        "\n",
        "        episode_returns = []\n",
        "        episode_lengths = []\n",
        "\n",
        "        for episode_num in range(n_episodes):\n",
        "            obs, _ = env.reset()\n",
        "            total_return = 0.0\n",
        "            steps = 0\n",
        "\n",
        "            done = False\n",
        "            while not done:\n",
        "                action = algo.predict(np.expand_dims(obs, axis=0))[0]\n",
        "                obs, reward, terminated, truncated, _ = env.step(action)\n",
        "                total_return += reward\n",
        "                steps += 1\n",
        "\n",
        "                done = terminated or truncated\n",
        "                if max_steps and steps >= max_steps:\n",
        "                    done = True\n",
        "\n",
        "            episode_returns.append(total_return)\n",
        "            episode_lengths.append(steps)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"  Episode {episode_num + 1:3d}: Return = {total_return:8.2f}, Steps = {steps:3d}\")\n",
        "\n",
        "        mean_return = float(np.mean(episode_returns))\n",
        "        std_return = float(np.std(episode_returns))\n",
        "        mean_length = float(np.mean(episode_lengths))\n",
        "\n",
        "        stats = {\n",
        "            'mean_return': mean_return,\n",
        "            'std_return': std_return,\n",
        "            'max_return': float(np.max(episode_returns)),\n",
        "            'min_return': float(np.min(episode_returns)),\n",
        "            'mean_episode_length': mean_length,\n",
        "        }\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\nOK Evaluation Complete!\")\n",
        "            print(f\"  - Mean Return: {mean_return:.4f} +/- {std_return:.4f}\")\n",
        "\n",
        "        return stats\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL PERSISTENCE\n",
        "# ============================================================================\n",
        "\n",
        "class ModelManager:\n",
        "    \"\"\"Handler for saving and loading models.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def save_model(algo, save_path: str = \"./offline_rl_model\") -> None:\n",
        "        \"\"\"Save a trained model.\"\"\"\n",
        "        print(f\"\\nSaving model to {save_path}...\")\n",
        "        algo.save_model(save_path)\n",
        "        print(f\"OK Model saved successfully!\")\n",
        "\n",
        "    @staticmethod\n",
        "    def load_model(\n",
        "        algo_type: str,\n",
        "        save_path: str = \"./offline_rl_model\",\n",
        "        device: str = \"cpu:0\"\n",
        "    ):\n",
        "        \"\"\"Load a trained model.\"\"\"\n",
        "        print(f\"\\nLoading model from {save_path}...\")\n",
        "        config_class = OfflineRLAlgorithm.ALGORITHM_CONFIGS[algo_type.lower()]['config_class']\n",
        "        algo = config_class().create(device=device)\n",
        "        algo.load_model(save_path)\n",
        "        print(f\"OK Model loaded successfully!\")\n",
        "        return algo"
      ],
      "metadata": {
        "id": "gLExY9uer_OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMPLETE PIPELINE & MAIN EXECUTION"
      ],
      "metadata": {
        "id": "dTGcdSvIycMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# COMPLETE PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def main(\n",
        "    episodes_data:      List[Dict],  # Accept episodes data directly\n",
        "    algo_type:  str = 'cql',\n",
        "    n_steps:  int = 100000,\n",
        "    n_eval_episodes: int = 5,\n",
        "    device:  str = 'cpu:  0',\n",
        "    save_model_flag:  bool = True\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Complete offline RL pipeline.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"OFFLINE DEEP REINFORCEMENT LEARNING PIPELINE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    OfflineRLAlgorithm.  list_algorithms()\n",
        "\n",
        "    # Create replay buffer directly from episodes\n",
        "    try:\n",
        "        # ✅ Convert dict episodes to d3rlpy Episode objects\n",
        "        from d3rlpy.dataset import Episode\n",
        "\n",
        "        d3rlpy_episodes = []\n",
        "        for episode_dict in episodes_data:\n",
        "            # ✅ Episode requires (observations, actions, rewards, terminated:   bool)\n",
        "            # terminated should be True if episode ended, False otherwise\n",
        "            episode = Episode(\n",
        "                observations=episode_dict['observations'],\n",
        "                actions=episode_dict['actions'],\n",
        "                rewards=episode_dict['rewards'],\n",
        "                terminated=True  # ✅ Mark as terminated (episode finished)\n",
        "            )\n",
        "            d3rlpy_episodes.append(episode)\n",
        "\n",
        "        # Now create replay buffer with proper Episode objects\n",
        "        replay_buffer = d3rlpy.dataset.create_fifo_replay_buffer(\n",
        "            episodes=d3rlpy_episodes,\n",
        "            limit=1000000  # 1 million transitions max\n",
        "        )\n",
        "        print(f\"\\nOK ReplayBuffer created successfully!\")\n",
        "        # ✅ Use size() method or get total_transitions\n",
        "        buffer_size = replay_buffer.size()\n",
        "        print(f\"  - Size: {buffer_size} transitions\")\n",
        "        results['replay_buffer_size'] = buffer_size\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR creating replay buffer: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        raise\n",
        "\n",
        "    algo = OfflineRLAlgorithm.  create(algo_type=algo_type, device=device)\n",
        "    results['algorithm'] = algo_type\n",
        "\n",
        "    training_stats = OfflineRLTrainer. train(\n",
        "        algo=algo,\n",
        "        replay_buffer=replay_buffer,\n",
        "        n_steps=n_steps,\n",
        "        save_interval=max(1000, n_steps // 10),\n",
        "        verbose=True\n",
        "    )\n",
        "    results['training_stats'] = training_stats\n",
        "\n",
        "    try:\n",
        "        from gymnasium.  wrappers import TimeLimit\n",
        "        eval_env = TimeLimit(\n",
        "            SimglucoseGymEnv(patient_name='adolescent#001', seed=42),\n",
        "            max_episode_steps=480\n",
        "        )\n",
        "\n",
        "        eval_stats = PolicyEvaluator.evaluate(\n",
        "            algo=algo,\n",
        "            env=eval_env,\n",
        "            n_episodes=n_eval_episodes,\n",
        "            max_steps=480,\n",
        "            verbose=True\n",
        "        )\n",
        "        results['evaluation_stats'] = eval_stats\n",
        "        eval_env.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nWARNING Error during evaluation: {e}\")\n",
        "\n",
        "    if save_model_flag:\n",
        "        model_path = f\"./offline_rl_{algo_type}_model\"\n",
        "        ModelManager.save_model(algo, save_path=model_path)\n",
        "        results['model_path'] = model_path\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"TRAINING SUMMARY\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"OK Pipeline Complete!\")\n",
        "    print(f\"\\nResults:\")\n",
        "    print(f\"  - Algorithm: {results['algorithm']}\")\n",
        "    print(f\"  - Training Steps: {results['training_stats']['n_steps']}\")\n",
        "    print(f\"  - Training Time: {results['training_stats']['training_time']:.2f}s\")\n",
        "    print(f\"  - Replay Buffer Size: {results['replay_buffer_size']}\")\n",
        "\n",
        "    if 'evaluation_stats' in results:\n",
        "        eval_stats = results['evaluation_stats']\n",
        "        print(f\"  - Evaluation Mean Return: {eval_stats['mean_return']:.4f} +/- {eval_stats['std_return']:.4f}\")\n",
        "\n",
        "    if 'model_path' in results:\n",
        "        print(f\"  - Model Saved:   {results['model_path']}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 70)\n",
        "    print(\"PHASE 1: ENVIRONMENT VERIFICATION\")\n",
        "    print(\"=\" * 70)\n",
        "    # ...  Phase 1 code unchanged ...\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"PHASE 2: DATA COLLECTION\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    episodes_data = None\n",
        "    try:\n",
        "        episodes_data = collect_data_and_save(\n",
        "            num_episodes=10,\n",
        "            max_steps_per_episode=480,\n",
        "            patient_name='adolescent#001',\n",
        "            policy_type='random'\n",
        "        )\n",
        "        print(f\"OK Collected {len(episodes_data)} episodes\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR during data collection: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"PHASE 3: OFFLINE RL TRAINING\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    try:\n",
        "        if episodes_data is not None:\n",
        "            results = main(\n",
        "                episodes_data=episodes_data,\n",
        "                algo_type='cql',\n",
        "                n_steps=50000,\n",
        "                n_eval_episodes=3,\n",
        "                device='cpu:0',\n",
        "                save_model_flag=True\n",
        "            )\n",
        "            print(\"\\n\" + \"=\" * 80)\n",
        "            print(\"OK TRAINING COMPLETE!\")\n",
        "            print(\"=\" * 80)\n",
        "        else:\n",
        "            print(\"WARNING: No episodes collected.  Skipping training.\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR during training: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"OK COMPLETE OFFLINE DRL PIPELINE FINISHED!\")\n",
        "    print(\"=\" * 80)"
      ],
      "metadata": {
        "id": "lCjyP40RsI52"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMGgOkvQMbYrLEVQr+RN4HD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}